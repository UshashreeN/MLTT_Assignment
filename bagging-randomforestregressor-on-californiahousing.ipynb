{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-20T04:09:59.534717Z",
     "iopub.status.busy": "2023-12-20T04:09:59.534099Z",
     "iopub.status.idle": "2023-12-20T04:09:59.545052Z",
     "shell.execute_reply": "2023-12-20T04:09:59.543478Z",
     "shell.execute_reply.started": "2023-12-20T04:09:59.534663Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Random Forest Regressor on California Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T04:10:04.114149Z",
     "iopub.status.busy": "2023-12-20T04:10:04.113509Z",
     "iopub.status.idle": "2023-12-20T04:10:04.122609Z",
     "shell.execute_reply": "2023-12-20T04:10:04.121157Z",
     "shell.execute_reply.started": "2023-12-20T04:10:04.114098Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix,\\\n",
    "ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split,\\\n",
    "cross_validate, cross_val_score, ShuffleSplit, \\\n",
    "RandomizedSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T04:10:04.805321Z",
     "iopub.status.busy": "2023-12-20T04:10:04.804849Z",
     "iopub.status.idle": "2023-12-20T04:10:04.812136Z",
     "shell.execute_reply": "2023-12-20T04:10:04.810615Z",
     "shell.execute_reply.started": "2023-12-20T04:10:04.805283Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(306) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `ShuffleSplit` as cv with 10 splits and 20% e.g. set aside as test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T04:10:13.727511Z",
     "iopub.status.busy": "2023-12-20T04:10:13.726974Z",
     "iopub.status.idle": "2023-12-20T04:10:13.735493Z",
     "shell.execute_reply": "2023-12-20T04:10:13.733923Z",
     "shell.execute_reply.started": "2023-12-20T04:10:13.727471Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the data and split it into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T04:10:14.758958Z",
     "iopub.status.busy": "2023-12-20T04:10:14.758436Z",
     "iopub.status.idle": "2023-12-20T04:10:34.850479Z",
     "shell.execute_reply": "2023-12-20T04:10:34.846904Z",
     "shell.execute_reply.started": "2023-12-20T04:10:14.758918Z"
    }
   },
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "features, labels = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "labels *=100\n",
    "\n",
    "# train-test split\n",
    "com_train_features, test_features, com_train_labels, test_labels = \\\n",
    "    train_test_split(features, labels, random_state=42)\n",
    "\n",
    "# train --> train + dev split\n",
    "train_features, dev_features, train_labels, dev_labels = \\\n",
    "    train_test_split(com_train_features, com_train_labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training different regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train different regressors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-20T04:10:34.851593Z",
     "iopub.status.idle": "2023-12-20T04:10:34.852160Z",
     "shell.execute_reply": "2023-12-20T04:10:34.851919Z",
     "shell.execute_reply.started": "2023-12-20T04:10:34.851895Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_regressor(estimator, X_train, y_train, cv, name):\n",
    "    cv_results = cross_validate(estimator,\n",
    "                               X_train,\n",
    "                               y_train,\n",
    "                               cv=cv,\n",
    "                               scoring=\"neg_mean_absolute_error\",\n",
    "                               return_train_score=True,\n",
    "                               return_estimator=True)\n",
    "    \n",
    "    cv_train_error = -1 * cv_results['train_score']\n",
    "    cv_test_error = -1 * cv_results['test_score']\n",
    "    \n",
    "    print(f\"On an average, {name} makes an error of \"\n",
    "          f\"{cv_train_error.mean():.3f}k +/- {cv_train_error.std():.3f}k on the training set.\")\n",
    "    print(f\"On an average, {name} makes an error of \"\n",
    "          f\"{cv_test_error.mean():.3f}k +/- {cv_test_error.std():.3f}k on the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-20T04:10:34.854879Z",
     "iopub.status.idle": "2023-12-20T04:10:34.855378Z",
     "shell.execute_reply": "2023-12-20T04:10:34.855175Z",
     "shell.execute_reply.started": "2023-12-20T04:10:34.855154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On an average, decision tree regressor makes an error of 0.000k +/- 0.000k on the training set.\n",
      "On an average, decision tree regressor makes an error of 47.259k +/- 1.142k on the test set.\n"
     ]
    }
   ],
   "source": [
    "#title Decision Tree Regressor\n",
    "train_regressor(\n",
    "    DecisionTreeRegressor(), com_train_features,\n",
    "    com_train_labels, cv, 'decision tree regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-20T04:10:34.857976Z",
     "iopub.status.idle": "2023-12-20T04:10:34.858475Z",
     "shell.execute_reply": "2023-12-20T04:10:34.858269Z",
     "shell.execute_reply.started": "2023-12-20T04:10:34.858247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On an average, bagging regressor makes an error of 14.377k +/- 0.196k on the training set.\n",
      "On an average, bagging regressor makes an error of 35.217k +/- 0.608k on the test set.\n"
     ]
    }
   ],
   "source": [
    "#title Bagging Regressor\n",
    "train_regressor(\n",
    "    BaggingRegressor(), com_train_features,\n",
    "    com_train_labels, cv, 'bagging regressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-20T04:10:34.861466Z",
     "iopub.status.idle": "2023-12-20T04:10:34.862410Z",
     "shell.execute_reply": "2023-12-20T04:10:34.862116Z",
     "shell.execute_reply.started": "2023-12-20T04:10:34.862067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On an average, random forest regressor makes an error of 12.642k +/- 0.071k on the training set.\n",
      "On an average, random forest regressor makes an error of 33.198k +/- 0.717k on the test set.\n"
     ]
    }
   ],
   "source": [
    "train_regressor(\n",
    "    RandomForestRegressor(), com_train_features,\\\n",
    "    com_train_labels, cv, 'random forest regressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter search for random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-20T04:10:34.868152Z",
     "iopub.status.idle": "2023-12-20T04:10:34.869536Z",
     "shell.execute_reply": "2023-12-20T04:10:34.869239Z",
     "shell.execute_reply.started": "2023-12-20T04:10:34.869207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>40.641923</td>\n",
       "      <td>0.733708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>41.081103</td>\n",
       "      <td>0.921070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>43.872041</td>\n",
       "      <td>0.802726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>45.717665</td>\n",
       "      <td>1.180473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>49.465011</td>\n",
       "      <td>1.167198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>49.480914</td>\n",
       "      <td>1.021785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>50.056112</td>\n",
       "      <td>1.445609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>55.022199</td>\n",
       "      <td>1.076063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>61.822161</td>\n",
       "      <td>1.052154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>73.288226</td>\n",
       "      <td>1.257658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_leaf_nodes  mean_test_error  std_test_error\n",
       "0                500                  100        40.641923        0.733708\n",
       "2                 10                  100        41.081103        0.921070\n",
       "7                100                   50        43.872041        0.802726\n",
       "8                  1                  100        45.717665        1.180473\n",
       "6                 50                   20        49.465011        1.167198\n",
       "1                100                   20        49.480914        1.021785\n",
       "9                 10                   20        50.056112        1.445609\n",
       "3                500                   10        55.022199        1.076063\n",
       "4                  5                    5        61.822161        1.052154\n",
       "5                  5                    2        73.288226        1.257658"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    \"n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "search_cv = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2), param_distributions=param_distributions,\n",
    "    scoring=\"neg_mean_absolute_error\", n_iter=10, random_state=0, n_jobs=2,)\n",
    "\n",
    "search_cv.fit(com_train_features, com_train_labels)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"mean_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-20T04:10:34.871254Z",
     "iopub.status.idle": "2023-12-20T04:10:34.871779Z",
     "shell.execute_reply": "2023-12-20T04:10:34.871556Z",
     "shell.execute_reply.started": "2023-12-20T04:10:34.871533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, our random forest regressor makes an error of 40.46 k$\n"
     ]
    }
   ],
   "source": [
    "error = -search_cv.score(test_features, test_labels)\n",
    "print(f\"On average, our random forest regressor makes an error of {error:.2f} k$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'max_leaf_nodes': 100, 'n_estimators': 100}\n",
      "\n",
      "Best Mean Test Error: 40.55061229196913\n",
      "\n",
      "Results Table:\n",
      "   param_n_estimators param_max_leaf_nodes  mean_test_error  std_test_error\n",
      "51                100                  100        40.550612        0.756845\n",
      "53                500                  100        40.610522        0.693956\n",
      "52                200                  100        40.613473        0.802481\n",
      "50                 50                  100        40.722904        0.728099\n",
      "49                 20                  100        41.035598        0.882256\n",
      "48                 10                  100        41.446081        0.773629\n",
      "47                  5                  100        41.921071        0.773260\n",
      "46                  2                  100        43.729194        0.683593\n",
      "44                500                   50        43.773841        0.832582\n",
      "41                 50                   50        43.796824        0.819423\n",
      "42                100                   50        43.834062        0.729886\n",
      "40                 20                   50        43.881667        1.109900\n",
      "43                200                   50        43.882336        0.826883\n",
      "39                 10                   50        44.414069        0.690507\n",
      "38                  5                   50        44.834047        1.034235\n",
      "37                  2                   50        46.830572        1.274405\n",
      "45                  1                  100        47.206125        1.232793\n",
      "35                500                   20        49.459799        1.083064\n",
      "31                 20                   20        49.493348        1.013789\n",
      "33                100                   20        49.513996        1.032586\n",
      "34                200                   20        49.516585        1.032485\n",
      "36                  1                   50        49.590287        1.082783\n",
      "32                 50                   20        49.606791        1.144723\n",
      "30                 10                   20        49.945249        1.098132\n",
      "29                  5                   20        50.422304        1.093535\n",
      "28                  2                   20        51.625285        1.073311\n",
      "27                  1                   20        53.554794        1.286804\n",
      "25                200                   10        55.026410        1.015200\n",
      "24                100                   10        55.028791        1.054578\n",
      "23                 50                   10        55.035263        1.060605\n",
      "26                500                   10        55.049547        1.028975\n",
      "21                 10                   10        55.232050        1.126444\n",
      "22                 20                   10        55.299195        1.114165\n",
      "20                  5                   10        55.521721        1.298371\n",
      "19                  2                   10        56.847811        1.292363\n",
      "18                  1                   10        58.161148        0.900437\n",
      "17                500                    5        61.209271        1.054021\n",
      "12                 10                    5        61.211613        1.209678\n",
      "16                200                    5        61.232972        1.026902\n",
      "13                 20                    5        61.242690        1.052412\n",
      "15                100                    5        61.256161        1.077360\n",
      "11                  5                    5        61.326887        0.998476\n",
      "14                 50                    5        61.391745        1.005879\n",
      "10                  2                    5        61.842120        0.951427\n",
      "9                   1                    5        62.560931        0.869451\n",
      "8                 500                    2        72.965381        1.046559\n",
      "5                  50                    2        73.008599        1.089444\n",
      "4                  20                    2        73.015276        1.061588\n",
      "7                 200                    2        73.024375        1.036095\n",
      "6                 100                    2        73.026407        1.026133\n",
      "2                   5                    2        73.112776        1.008032\n",
      "3                  10                    2        73.283499        1.169455\n",
      "1                   2                    2        74.227340        0.881880\n",
      "0                   1                    2        74.292386        0.884477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_cv = GridSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_cv.fit(com_train_features, com_train_labels)\n",
    "\n",
    "# Extract and display the results\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(grid_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "result_table = cv_results[columns].sort_values(by=\"mean_test_error\")\n",
    "\n",
    "# Display the best parameters and corresponding mean test error\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_cv.best_params_)\n",
    "print(\"\\nBest Mean Test Error:\", -grid_cv.best_score_)\n",
    "print(\"\\nResults Table:\")\n",
    "print(result_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'regressor__n_estimators': 50, 'regressor__max_leaf_nodes': 100}\n",
      "\n",
      "Best Mean Test Error: 54.1448868729796\n",
      "\n",
      "Results Table:\n",
      "  param_regressor__n_estimators param_regressor__max_leaf_nodes  \\\n",
      "4                            50                             100   \n",
      "8                           200                              20   \n",
      "6                             2                              50   \n",
      "2                             2                              20   \n",
      "0                           500                              10   \n",
      "7                            50                              10   \n",
      "3                            10                              10   \n",
      "9                            50                               5   \n",
      "5                            50                               2   \n",
      "1                             5                               2   \n",
      "\n",
      "   mean_test_error  std_test_error  \n",
      "4        54.144887        1.103991  \n",
      "8        54.705657        1.145223  \n",
      "6        54.929819        1.162768  \n",
      "2        55.294425        1.085424  \n",
      "0        56.933379        1.070925  \n",
      "7        57.027777        1.087156  \n",
      "3        57.054679        1.118944  \n",
      "9        61.234983        1.094016  \n",
      "5        73.075147        1.059267  \n",
      "1        73.258277        1.373636  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hyperparameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    \"regressor__n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"regressor__max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "# Instantiate the RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_jobs=2)\n",
    "\n",
    "# Create a pipeline with feature selection and regression\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(rf_reg)),\n",
    "    ('scaler', StandardScaler()),  # You can add other preprocessing steps here\n",
    "    ('regressor', rf_reg)\n",
    "])\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_iter=10,  # Number of parameter settings sampled\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "randomized_cv.fit(com_train_features, com_train_labels)\n",
    "\n",
    "# Extract and display the results\n",
    "columns = [f\"param_{name}\" for name in param_dist.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(randomized_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "result_table = cv_results[columns].sort_values(by=\"mean_test_error\")\n",
    "\n",
    "# Display the best parameters and corresponding mean test error\n",
    "print(\"Best Parameters:\")\n",
    "print(randomized_cv.best_params_)\n",
    "print(\"\\nBest Mean Test Error:\", -randomized_cv.best_score_)\n",
    "print(\"\\nResults Table:\")\n",
    "print(result_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'regressor__n_estimators': 10, 'regressor__max_leaf_nodes': 100}\n",
      "\n",
      "Best Mean Test Error: 54.28954231618407\n",
      "\n",
      "Results Table:\n",
      "  param_regressor__n_estimators param_regressor__max_leaf_nodes  \\\n",
      "6                            10                             100   \n",
      "1                           100                              10   \n",
      "7                            20                              10   \n",
      "3                             1                              10   \n",
      "9                            50                               5   \n",
      "8                             2                               5   \n",
      "4                            10                               2   \n",
      "2                            50                               2   \n",
      "5                           500                               2   \n",
      "0                             5                               2   \n",
      "\n",
      "   mean_test_error  std_test_error  \n",
      "6        54.289542        1.127776  \n",
      "1        56.894332        1.054914  \n",
      "7        57.062584        1.058496  \n",
      "3        58.529653        0.635195  \n",
      "9        61.270648        1.140876  \n",
      "8        62.221819        1.262790  \n",
      "4        72.941899        1.130796  \n",
      "2        72.985166        0.930381  \n",
      "5        73.005012        1.073371  \n",
      "0        73.275123        1.024800  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define the hyperparameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    \"regressor__n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"regressor__max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "\n",
    "# Instantiate the RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_jobs=2)\n",
    "\n",
    "# Create a pipeline with feature selection and regression\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(rf_reg)),\n",
    "    ('scaler', StandardScaler()),  # You can add other preprocessing steps here\n",
    "    ('regressor', rf_reg)\n",
    "])\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_iter=10,  # Number of parameter settings sampled\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "randomized_cv.fit(com_train_features, com_train_labels)\n",
    "\n",
    "# Extract and display the results\n",
    "columns = [f\"param_{name}\" for name in param_dist.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(randomized_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "result_table = cv_results[columns].sort_values(by=\"mean_test_error\")\n",
    "\n",
    "# Display the best parameters and corresponding mean test error\n",
    "print(\"Best Parameters:\")\n",
    "print(randomized_cv.best_params_)\n",
    "print(\"\\nBest Mean Test Error:\", -randomized_cv.best_score_)\n",
    "print(\"\\nResults Table:\")\n",
    "print(result_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30213,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
